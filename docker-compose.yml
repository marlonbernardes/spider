version: '3.3'
services:

  # Where the URLs of the pages that have already been crawled
  # are stored.
  redis:
    image: redis:5
    container_name: spider_redis
    ports:
      - 6379:6379

  # Elastic is used to persist and index the textual content
  # of the pages that have been crawled.
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.4.0
    container_name: spider_es
    environment:
      - node.name=spider_es_1
      - cluster.name=docker-cluster
      - cluster.initial_master_nodes=spider_es_1
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms256M -Xmx256M"
      - http.cors.enabled=true
      - http.cors.allow-origin=*
      - network.host=_eth0_
    ulimits:
      nproc: 65535
      memlock:
        soft: -1
        hard: -1
    cap_add:
      - ALL
    ports:
      - 9200:9200
      - 9300:9300

  zookeeper:
    image: wurstmeister/zookeeper
    container_name: spider_zookeeper
    ports:
      - 2181:2181

  kafka:
    image: wurstmeister/kafka
    container_name: spider_kafka
    ports:
      - 9092:9092
    environment:
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_ADVERTISED_HOST_NAME: 192.168.0.208
      KAFKA_CREATE_TOPICS: "spider.crawling_queue:3:1"
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
